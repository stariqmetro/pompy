{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "219113fb",
   "metadata": {},
   "source": [
    "Import the necessary libraries, keeping the python standard ones above the non-standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9603683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1c6d213",
   "metadata": {},
   "source": [
    "Assign path variables. This way we can easily change the path later if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc71fdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORT_PATH = \"//filesrv/MercuryGate/\"\n",
    "PARQUET_PATH = \"//filesrv/MercuryGate/Separated/Backup.parquet\"\n",
    "ORDERS_PATH = \"C:/OneDrive - Metropolitan Warehouse/Vendor Control/Data Files/POM Level/Pull Sheet Data LH Team/\"\n",
    "TICKETS_PATH = \"C:/OneDrive - Metropolitan Warehouse/Vendor Control/Data Files/POM Level/Closing Tickets/\"\n",
    "OUTPUT_PATH = \"C:/OneDrive - Metropolitan Warehouse/Vendor Control/Data Files/POM Level/TMSProduct/\"\n",
    "AUTO_PULL_PATH = \"C:/OneDrive - Metropolitan Warehouse/Vendor Control/Data Files/POM Level/pompy/get_missing_pull_sheets.py\"\n",
    "AUTO_TICKETS_PATH = \"C:/OneDrive - Metropolitan Warehouse/Vendor Control/Data Files/POM Level/pompy/get_missing_closing_tickets.py\"\n",
    "AUTO_DIST_PATH = \"C:/OneDrive - Metropolitan Warehouse/Vendor Control/Data Files/POM Level/pompy/get_missing_dist.py\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4562e180",
   "metadata": {},
   "source": [
    "Read all reports in the report path and create a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d4a22f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_files = glob(os.path.join(REPORT_PATH, \"*.csv\"))\n",
    "if len(report_files) > 0:\n",
    "    df = pd.concat((pd.read_csv(f) for f in report_files), ignore_index=True)\n",
    "    df = df.drop_duplicates()\n",
    "else:\n",
    "    print(\"Nothing to read. Exiting...\")\n",
    "    exit(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a502255",
   "metadata": {},
   "source": [
    "Concat the old data to the newer one, replacing any data in the old with the new one.<br>\n",
    "Archive it in a parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "452a3d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(PARQUET_PATH):\n",
    "        pqt_df = pd.read_parquet(PARQUET_PATH)\n",
    "        pqt_df = pqt_df.loc[~pqt_df['Primary Reference'].isin(df['Primary Reference'])]\n",
    "        pqt_df = pd.concat([pqt_df, df], ignore_index=True)\n",
    "        pqt_df.astype(str).to_parquet(PARQUET_PATH, index=False)\n",
    "else:\n",
    "        df.astype(str).to_parquet(PARQUET_PATH, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ebdeefd",
   "metadata": {},
   "source": [
    "Get the columns in the cols list only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dabf8b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Primary Reference', 'Pinnacle Manifest No', 'Target Ship (Late)',\n",
    "        'Arrival Date', 'Target Delivery (Late)', 'Actual Delivery', 'Origin Code',\n",
    "        'Origin Zip', 'Dest Code', 'Dest Zip', 'Carrier', 'Carrier Total',\n",
    "        'Invoice Charge', 'Invoice Date', 'Invoice Number', 'Invoice Total Line Haul',\n",
    "        'Invoice Total Fuel']\n",
    "df = df[cols]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b18eece5",
   "metadata": {},
   "source": [
    "Before we can use the Carrier Total, we need to replace it with the Invoice Charge.<br>\n",
    "Before we can use Invoice Charge, we need to aggregate it over the load.<br>\n",
    "Before we can aggregate it over the load, we need to divide it over multiple loads if its loads > 1.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f32ed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide the invoices equally over their loads, no effect if only 1 load\n",
    "number_of_loads_against_invoice = df.groupby('Invoice Number')['Primary Reference'].transform('nunique')\n",
    "df['Invoice Charge'] = df['Invoice Charge'] / number_of_loads_against_invoice\n",
    "df['Invoice Total Line Haul'] = df['Invoice Total Line Haul'] / number_of_loads_against_invoice\n",
    "df['Invoice Total Fuel'] = df['Invoice Total Fuel'] / number_of_loads_against_invoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23ee4349",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate costs against reference, summing against unique invoices\n",
    "df_gb = df.groupby([\n",
    "    'Primary Reference',\n",
    "    'Invoice Number'])[[\n",
    "        'Invoice Charge',\n",
    "        'Invoice Total Line Haul',\n",
    "        'Invoice Total Fuel']].max().groupby(level='Primary Reference').sum()\n",
    "df = df.drop(columns=['Invoice Charge',\n",
    "                      'Invoice Total Line Haul',\n",
    "                      'Invoice Total Fuel'])\n",
    "df = df.merge(df_gb, on='Primary Reference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a423201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate invoice number to create a list, and aggregate invoice date to get max\n",
    "df['Invoice Number'] = df.groupby('Primary Reference')['Invoice Number'].transform(lambda x: \";\".join(set(x)))\n",
    "df['Invoice Date'] = df.groupby('Primary Reference')['Invoice Date'].transform('max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71f06238",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace 0s with nans to fillna later\n",
    "df['Invoice Charge'] = df['Invoice Charge'].replace(to_replace=0, value=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad9314f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace carrier total with invoice charge if invoice charge is not na\n",
    "df['Carrier Total'] = df['Invoice Charge'].fillna(df['Carrier Total'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db28273b",
   "metadata": {},
   "source": [
    "Drop duplicates from the dataframe using the subset of columns and keeping the last ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cdcf30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['Primary Reference', 'Pinnacle Manifest No', 'Origin Code',\n",
    "                           'Dest Code','Target Ship (Late)'], inplace=True, keep='last')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad20cf52",
   "metadata": {},
   "source": [
    "Fill any missing codes with their respective zips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf860505",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Origin Code'].fillna(df['Origin Zip'], inplace=True)\n",
    "df['Dest Code'].fillna(df['Dest Zip'], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78c6566d",
   "metadata": {},
   "source": [
    "Join Origin Code and Dest Code using \" | \" to create from_to.<br>\n",
    "Join Origin Zip and Dest Zip using \";\" to create from_to_zip.<br>\n",
    "Join origin code with origin zip and dest code with dest zip using \";\".<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22e80475",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"from_to\"] = df[\"Origin Code\"].astype('str') + \" | \" + df[\"Dest Code\"].astype('str')\n",
    "df[\"from_to_zip\"] = df[\"Origin Zip\"].astype('str') + \";\" + df[\"Dest Zip\"].astype('str')\n",
    "df[\"Code;Zip\"] = df[\"Dest Code\"].astype('str') + \";\" + df[\"Dest Zip\"].astype('str')\n",
    "df[\"OriginCode;Zip\"] = df[\"Origin Code\"].astype('str') + \";\" + df[\"Origin Zip\"].astype('str')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a3424fd",
   "metadata": {},
   "source": [
    "Convert datetime columns to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76cc70dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Target Ship (Late)\"] = pd.to_datetime(df[\"Target Ship (Late)\"])\n",
    "df[\"Target Delivery (Late)\"] = pd.to_datetime(df[\"Target Delivery (Late)\"])\n",
    "df[\"Invoice Date\"] = pd.to_datetime(df[\"Invoice Date\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e915ce6c",
   "metadata": {},
   "source": [
    "### create_lane(load):\n",
    "\n",
    "This function uses the Primary Reference (the load ID) to find the ship datetimes, delivery datetimes,<br>\n",
    "origin codes + zips, and dest codes + zips against the reference.<br>\n",
    "Then, it appends the delivery dates to the ship dates and destinations to origins.<br>\n",
    "Then, it sorts them by the dates in an ascending order.<br>\n",
    "Then, it loops over the codes, adding them to a list if the current code is not the same as the previous code.<br>\n",
    "It also splits the code using \";\" to get the code and the zip parts separated.<br>\n",
    "Finally, it joins the codes list using \" | \" and the zips list using \";\".<br>\n",
    "It then returns the two strings.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e854af5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lane(load):\n",
    "    rows = df.loc[df['Primary Reference']==load, [\"Target Ship (Late)\", \"Target Delivery (Late)\",\n",
    "                                                    \"OriginCode;Zip\", \"Code;Zip\"]]\n",
    "    targets = pd.concat([rows[\"Target Ship (Late)\"], rows[\"Target Delivery (Late)\"]])\n",
    "    code_zips = pd.concat([rows[\"OriginCode;Zip\"], rows[\"Code;Zip\"]])\n",
    "    rows = pd.DataFrame({\"Target\": targets, \"Code\": code_zips}).sort_values(by=\"Target\")\n",
    "    l = ['']; li = ['']\n",
    "    for x in rows[\"Code\"]:\n",
    "        if l[-1] != x.split(\";\")[0]:\n",
    "            l.append(x.split(\";\")[0])\n",
    "            li.append(x.split(\";\")[1])\n",
    "    l = l[1:]\n",
    "    li = li[1:]\n",
    "    lane = \" | \".join(l)\n",
    "    zips = \";\".join(li)\n",
    "    return lane, zips\n",
    "\n",
    "df['lane'], df['zips'] = zip(*df['Primary Reference'].apply(create_lane))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0483834f",
   "metadata": {},
   "source": [
    "### process_manifest(manifest):\n",
    "\n",
    "This function takes the manifest, converts it to str, and splits it by \", \".<br>\n",
    "Then, it loops over the list created to process each manifest.<br>\n",
    "\n",
    "> If \"VEN\" is found in the capitalized manifest, \"Yes\" is appended to the is_vendor_pickup list,<br>\n",
    "> the manifest is converted to 0, and '- 53FT' is appended to the size list. Otherwise, \"No\" is appended.<br>\n",
    "> If 'ft' is found in the lower-cased manifest, 7 digits of the manifest are taken, and the whole<br>\n",
    "> manifest is taken into the size list. Otherwise, 6 digits are taken, and '- 53FT' is appended.<br>\n",
    "\n",
    "Finally, it returns the manifest, size, and is_vendor_pickup lists.<br>\n",
    "<br>\n",
    "__Note that the sizes of these lists should be the same to avoid problems later when exploding them.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e26a0f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_manifest(manifest):\n",
    "    manifest = str(manifest).strip().split(\", \")\n",
    "    size = []\n",
    "    is_vendor_pickup = []\n",
    "    for i, j in enumerate(manifest):\n",
    "        if \"VEN\" in j.upper() or \"PU\" in j.upper():\n",
    "            manifest[i] = 0\n",
    "            is_vendor_pickup.append(\"Yes\")\n",
    "            size.append('- 53FT')\n",
    "        else:\n",
    "            is_vendor_pickup.append(\"No\")\n",
    "            if 'ft' in j.lower():\n",
    "                manifest[i] = ''.join(filter(str.isdigit, j))[:7]\n",
    "                size.append(j)\n",
    "            else:\n",
    "                manifest[i] = ''.join(filter(str.isdigit, j))[:6]\n",
    "                size.append('- 53FT')\n",
    "    return manifest, size, is_vendor_pickup\n",
    "\n",
    "df['Pinnacle Manifest No'], df['size'], df['Vendor Pickup?'] = zip(*df['Pinnacle Manifest No'].apply(process_manifest))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4917c9e4",
   "metadata": {},
   "source": [
    "Explode the three lists generated. This means that the lists are opened up and the elements fill rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "affd2e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.explode(['Pinnacle Manifest No', 'size', 'Vendor Pickup?'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a135780f",
   "metadata": {},
   "source": [
    "Convert the manifest numbers to numeric, coercing any errors.<br>\n",
    "Coercing errors means that they're converted to NaN. We fillna with 0,<br>\n",
    "and convert the numbers to integers. Finally, we rename the column to 'manifest_num'.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da64b537",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pinnacle Manifest No'] = pd.to_numeric(df['Pinnacle Manifest No'], errors='coerce'\n",
    "                                           ).fillna(0).astype(int)\n",
    "df = df.rename(columns={'Pinnacle Manifest No': 'manifest_num'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00eec848",
   "metadata": {},
   "source": [
    "Show the first 10 rows of the df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d1edcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Primary Reference  manifest_num  Target Ship (Late)      Arrival Date  \\\n",
      "1   LD18189 (Load ID)             0 2022-10-20 15:00:00  2022-10-21 06:00   \n",
      "3   LD18196 (Load ID)             0 2022-10-21 11:00:00  2022-10-26 08:00   \n",
      "5   LD18204 (Load ID)             0 2022-10-21 15:00:00  2022-10-25 08:00   \n",
      "7   LD18205 (Load ID)             0 2022-10-21 13:00:00  2022-10-24 08:00   \n",
      "9   LD18226 (Load ID)             0 2022-10-23 08:00:00  2022-10-24 07:30   \n",
      "11  LD18248 (Load ID)             0 2022-10-22 23:45:00  2022-10-25 08:00   \n",
      "13  LD18271 (Load ID)             0 2022-10-24 11:00:00  2022-10-27 08:00   \n",
      "15  LD18273 (Load ID)             0 2022-10-24 11:00:00  2022-10-27 09:00   \n",
      "17  LD18288 (Load ID)             0 2022-10-24 16:00:00  2022-10-25 07:00   \n",
      "19  LD18294 (Load ID)             0 2022-10-21 15:00:00  2022-10-22 06:00   \n",
      "\n",
      "   Target Delivery (Late)   Actual Delivery Origin Code  Origin Zip Dest Code  \\\n",
      "1     2022-10-21 08:00:00  2022-10-21 08:00       ED-SC       29492     NC-SD   \n",
      "3     2022-10-25 14:00:00  2022-10-26 08:30       CA-EV       91752     NC-EH   \n",
      "5     2022-10-24 14:00:00  2022-10-25 09:30       CA-EV       91752     IN-IN   \n",
      "7     2022-10-25 14:00:00  2022-10-24 08:30       CA-EV       91752     GA-AT   \n",
      "9     2022-10-24 14:00:00  2022-10-24 08:30       CA-EV       91752     CA-HY   \n",
      "11    2022-10-25 11:00:00  2022-10-25 08:30       NC-SD       27263     LA-NO   \n",
      "13    2022-10-27 14:00:00  2022-10-27 08:30       CA-EV       91752     NJ-HS   \n",
      "15    2022-10-27 14:00:00  2022-10-27 10:30       CA-EV       91752     NC-EH   \n",
      "17    2022-10-25 11:00:00  2022-10-25 08:45       NC-SD       27263     OH-DY   \n",
      "19    2022-10-22 08:00:00  2022-10-22 08:00       ED-SC       29492     NC-SD   \n",
      "\n",
      "    Dest Zip  ... Invoice Total Line Haul  Invoice Total Fuel        from_to  \\\n",
      "1      27263  ...                 1250.00                0.00  ED-SC | NC-SD   \n",
      "3      27265  ...                 6700.00                0.00  CA-EV | NC-EH   \n",
      "5      46241  ...                 5950.00                0.00  CA-EV | IN-IN   \n",
      "7      30360  ...                 5800.00                0.00  CA-EV | GA-AT   \n",
      "9      94545  ...                 1340.00              352.00  CA-EV | CA-HY   \n",
      "11     70121  ...                 1762.88              676.82  NC-SD | LA-NO   \n",
      "13      8861  ...                 7600.00                0.00  CA-EV | NJ-HS   \n",
      "15     27265  ...                 6700.00                0.00  CA-EV | NC-EH   \n",
      "17     45424  ...                 1128.96              379.26  NC-SD | OH-DY   \n",
      "19     27263  ...                 1250.00                0.00  ED-SC | NC-SD   \n",
      "\n",
      "    from_to_zip     Code;Zip  OriginCode;Zip           lane         zips  \\\n",
      "1   29492;27263  NC-SD;27263     ED-SC;29492  ED-SC | NC-SD  29492;27263   \n",
      "3   91752;27265  NC-EH;27265     CA-EV;91752  CA-EV | NC-EH  91752;27265   \n",
      "5   91752;46241  IN-IN;46241     CA-EV;91752  CA-EV | IN-IN  91752;46241   \n",
      "7   91752;30360  GA-AT;30360     CA-EV;91752  CA-EV | GA-AT  91752;30360   \n",
      "9   91752;94545  CA-HY;94545     CA-EV;91752  CA-EV | CA-HY  91752;94545   \n",
      "11  27263;70121  LA-NO;70121     NC-SD;27263  NC-SD | LA-NO  27263;70121   \n",
      "13   91752;8861   NJ-HS;8861     CA-EV;91752  CA-EV | NJ-HS   91752;8861   \n",
      "15  91752;27265  NC-EH;27265     CA-EV;91752  CA-EV | NC-EH  91752;27265   \n",
      "17  27263;45424  OH-DY;45424     NC-SD;27263  NC-SD | OH-DY  27263;45424   \n",
      "19  29492;27263  NC-SD;27263     ED-SC;29492  ED-SC | NC-SD  29492;27263   \n",
      "\n",
      "      size Vendor Pickup?  \n",
      "1   - 53FT             No  \n",
      "3   - 53FT             No  \n",
      "5   - 53FT             No  \n",
      "7   - 53FT             No  \n",
      "9   - 53FT             No  \n",
      "11  - 53FT             No  \n",
      "13  - 53FT             No  \n",
      "15  - 53FT             No  \n",
      "17  - 53FT             No  \n",
      "19  - 53FT             No  \n",
      "\n",
      "[10 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fdaef263",
   "metadata": {},
   "source": [
    "Print the shape of the dataframe (rows and columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b125d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8850, 25)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "384ed1e8",
   "metadata": {},
   "source": [
    "Create a temporary df with refined manifest_nums, and store it in a csv so that it<br>\n",
    "can be accessed by the auto pulling scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e8e3e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdf = pd.DataFrame()\n",
    "tempdf[\"manifest_num\"] = df[\"manifest_num\"].drop_duplicates().dropna()\n",
    "tempdf.to_csv(OUTPUT_PATH + \"temp.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "baaf438b",
   "metadata": {},
   "source": [
    "Run the auto pulling scripts to get the Pull Sheet Data and the Closing Tickets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "453d6d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'C:/OneDrive - Metropolitan Warehouse/Vendor Control/Data Files/POM Level/pompy/get_missing_closing_tickets.py'], returncode=0, stdout=b'\\r\\nGetting the POMs...\\r\\n\\r\\nGetting Closing Tickets...\\r\\n(0,)\\r\\nSeries([], Name: OrderNo, dtype: object)\\r\\n\\r\\nNo missing nums found. Exiting...\\r\\n\\r\\n')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"python\", AUTO_PULL_PATH, OUTPUT_PATH], stdout=subprocess.PIPE)\n",
    "subprocess.run([\"python\", AUTO_TICKETS_PATH], stdout=subprocess.PIPE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7540ec76",
   "metadata": {},
   "source": [
    "Remove the temporary csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73af37c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(OUTPUT_PATH + \"temp.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57464f89",
   "metadata": {},
   "source": [
    "### get_leg(list_stops, delim):\n",
    "\n",
    "([A, B, C, A], \" | \") => [A | B, B | C, C | A]<br>\n",
    "Takes a list of stops and a delimiter to join the stops together using the delimiter.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0f136c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leg(list_stops, delim):\n",
    "    list_legs = []\n",
    "    for i in range(len(list_stops)-1):\n",
    "        list_legs.append(list_stops[i] + delim + list_stops[i+1])\n",
    "    return list_legs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82ce45dc",
   "metadata": {},
   "source": [
    "### revise_from_to(lane, zip_lane, from_to, from_to_zip, load):\n",
    "\n",
    "Checks if the from_to is not in the lane and processes it, otherwise<br>\n",
    "returns [from_to], [from_to_zip], and [].<br>\n",
    "<br>\n",
    "Finds the index of the origin and the destination+1 in the lane's stops.<br>\n",
    "Then, it creates a list of stops from the origin to destination.<br>\n",
    "Then, it uses the get_leg function to convert the list of stops to list of legs.<br>\n",
    "Likwise for the zip_lane.<br>\n",
    "In case of a ValueError, appends the primary reference to the err list.<br>\n",
    "<br>\n",
    "Returns revised_from_to, revised_zips, and erronous Primary Reference.<br>\n",
    "<br>\n",
    "__Note that the length of the two lists, revised and revised_zips, must be the same for explosion.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f317e200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def revise_from_to(lane, zip_lane, from_to, from_to_zip, load):\n",
    "    err = []\n",
    "    revised = [from_to]\n",
    "    revised_zips = [from_to_zip]\n",
    "    if from_to not in lane:\n",
    "        origin, destination = from_to.split(\" | \")\n",
    "        stops = lane.split(\" | \")\n",
    "        zips = zip_lane.split(\";\")\n",
    "        try:\n",
    "            origin_index = stops.index(origin)\n",
    "            destination_index = origin_index + stops[origin_index:].index(destination) + 1\n",
    "            revised_stops = stops[origin_index:destination_index]\n",
    "            revised_zips_list = zips[origin_index:destination_index]\n",
    "            revised = get_leg(revised_stops, \" | \")\n",
    "            revised_zips = get_leg(revised_zips_list, \";\")\n",
    "        except ValueError:\n",
    "            err.append(load)\n",
    "    return revised, revised_zips, err\n",
    "\n",
    "err_df = pd.DataFrame()\n",
    "df['revised_from_to'], df['revised_zips'], err_df['Load'] = zip(*df.apply(lambda x: revise_from_to(\n",
    "    x['lane'], x['zips'], x['from_to'], x['from_to_zip'], x['Primary Reference']), axis=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f00c83c",
   "metadata": {},
   "source": [
    "We explode the revised_from_to and revised_zips' list to access the contents inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d5166d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.explode(['revised_from_to', 'revised_zips'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b983a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count_leg'] = df.groupby([\"Primary Reference\", \"revised_from_to\"]).transform('size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67b5eef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31720    2.0\n",
       "31720    2.0\n",
       "Name: count_leg, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df['Primary Reference']==\"LD27907 (Load ID)\"), \"count_leg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce1567ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Zip  Distance\n",
      "0  91752;85043       323\n",
      "1  85043;85043         0\n",
      "2  85043;91752       324\n",
      "3  85043;27263      2102\n",
      "4  27263;85043      2119\n"
     ]
    }
   ],
   "source": [
    "distance_table = pd.read_csv(\"C:/OneDrive - Metropolitan Warehouse/Vendor Control/Data Files/POM Level/Helpers/ZipDistances.csv\", dtype={'Zip_Code': str})\n",
    "print(distance_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f7c5261",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_dist = pd.DataFrame()\n",
    "failed_dist['dist'] = df.loc[~df['revised_zips'].isin(distance_table['Zip']), 'revised_zips']\n",
    "failed_dist = failed_dist.drop_duplicates().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6932d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split column into multiple columns by delimiter\n",
    "if len(failed_dist.index) > 0:\n",
    "    failed_dist[['zip1', 'zip2']] = failed_dist['dist'].str.split(';', n=1, expand=True).dropna(how='any')\n",
    "    failed_dist.drop(columns=['dist'], inplace=True)\n",
    "    failed_dist.to_csv(OUTPUT_PATH+'temp_dist.csv', index=False)\n",
    "    subprocess.Popen([\"python\", AUTO_DIST_PATH]).wait()\n",
    "    os.remove(OUTPUT_PATH + \"temp_dist.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fee0e8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(zips):\n",
    "    try:\n",
    "        # both Zip and leg should be strings\n",
    "        dist = distance_table.loc[distance_table['Zip'] == zips, 'Distance'].iloc[0]\n",
    "        failed_dist = None\n",
    "    except:\n",
    "        dist = 0\n",
    "        failed_dist = zips\n",
    "    return dist, failed_dist\n",
    "\n",
    "exfailed_dist = pd.DataFrame()\n",
    "df[\"zip_distance\"], exfailed_dist['exdist'] = zip(*df['revised_zips'].apply(get_distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2cddbdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate adjusted distance for each row\n",
    "df['Adjusted Distance'] = df['zip_distance'] * df['count_leg']\n",
    "\n",
    "# drop duplicates\n",
    "df.drop_duplicates(['Primary Reference', 'revised_from_to'], inplace=True)\n",
    "\n",
    "# group by Primary Reference and transform the sum of adjusted distance\n",
    "df['Load Total Distance'] = df.groupby(['Primary Reference'])['Adjusted Distance'].transform('sum')\n",
    "\n",
    "# reset index\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e33156c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate number of manifests per leg\n",
    "legs_per_load = df.groupby(['Primary Reference']).revised_from_to.nunique().reset_index(name='Legs per Load')\n",
    "\n",
    "# merge manifests_per_leg with fact_table\n",
    "df = pd.merge(df, legs_per_load, on=['Primary Reference'])\n",
    "\n",
    "# allocate leg cost to manifests\n",
    "df['Leg Cost'] = np.where(df['Load Total Distance'] <= 0,\n",
    "                          df['Carrier Total'] / df['Legs per Load'].clip(lower=1),\n",
    "                          df['Carrier Total'] * df['Adjusted Distance'] / df['Load Total Distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8484ee98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting the POMs...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGetting the POMs...\")\n",
    "all_files = glob(os.path.join(ORDERS_PATH, \"*.csv\"))\n",
    "df_poms = pd.concat((pd.read_csv(f, encoding='ISO-8859-1', engine='c', dtype={'Manifest No': object,\n",
    "                                                                              'OrderNo': object},\n",
    "                                usecols=['Manifest No', 'OrderNo', 'Weight', 'Cu_Ft_']\n",
    "                                ) for f in all_files), ignore_index=True).drop_duplicates().round(2)\n",
    "df_pomsg = df_poms.groupby(['Manifest No', 'OrderNo'], as_index=False).agg({'Cu_Ft_': 'sum', 'Weight': 'sum'})\n",
    "df_pomsg['Count'] = df_poms.groupby(['Manifest No', 'OrderNo'], as_index=False).size().loc[:, 'size']\n",
    "df_poms = df_pomsg.set_index('OrderNo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ef34383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting Closing Tickets...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGetting Closing Tickets...\")\n",
    "kpi_files = glob(os.path.join(TICKETS_PATH, \"*.csv\"))\n",
    "df_kpi = pd.concat((pd.read_csv(f, encoding='ISO-8859-1', engine='c', dtype={'Order #': object},\n",
    "                                usecols=['Order #', 'Actual Delivery Date', 'Client Name', 'Amount']\n",
    "                                ) for f in kpi_files), ignore_index=True).drop_duplicates().round(2)\n",
    "df_kpi = df_kpi.groupby('Order #').agg({'Actual Delivery Date': 'first', 'Client Name': 'first', 'Amount': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c83c4656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merging df_poms and closing_tickets...\n",
      "(1191040, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMerging df_poms and closing_tickets...\")\n",
    "df_poms = df_poms.join(df_kpi)\n",
    "df_poms.index.names = ['Order #']\n",
    "df_poms.reset_index(inplace=True)\n",
    "print(df_poms.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c65623f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merging fact_table and df_poms...\n",
      "(75772, 40)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMerging fact_table and df_poms...\")\n",
    "df_poms['Manifest No'] = df_poms['Manifest No'].fillna(0).astype(int)\n",
    "df_poms.set_index('Manifest No', inplace=True)\n",
    "df.set_index('manifest_num', inplace=True)\n",
    "fact_table = df.join(df_poms)\n",
    "fact_table.index.names = ['manifest_num']\n",
    "fact_table.reset_index(inplace=True)\n",
    "print(fact_table.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa876e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shahmir.tariq\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\arrays\\timedeltas.py:908: RuntimeWarning: invalid value encountered in cast\n",
      "  base = data.astype(np.int64)\n",
      "c:\\Users\\shahmir.tariq\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\arrays\\timedeltas.py:912: RuntimeWarning: invalid value encountered in cast\n",
      "  data = (base * m + (frac * m).astype(np.int64)).view(\"timedelta64[ns]\")\n"
     ]
    }
   ],
   "source": [
    "fact_table['Order Delivery Date'] = (pd.TimedeltaIndex(fact_table['Actual Delivery Date'\n",
    "                                            ], unit='d') + datetime(1899, 12, 30)).strftime('%Y-%m-%d')\n",
    "fact_table.drop(columns=['Actual Delivery Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6efd3097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manifest_num</th>\n",
       "      <th>Primary Reference</th>\n",
       "      <th>Target Ship (Late)</th>\n",
       "      <th>Arrival Date</th>\n",
       "      <th>Target Delivery (Late)</th>\n",
       "      <th>Actual Delivery</th>\n",
       "      <th>Origin Code</th>\n",
       "      <th>Origin Zip</th>\n",
       "      <th>Dest Code</th>\n",
       "      <th>Dest Zip</th>\n",
       "      <th>...</th>\n",
       "      <th>Load Total Distance</th>\n",
       "      <th>Legs per Load</th>\n",
       "      <th>Leg Cost</th>\n",
       "      <th>Order #</th>\n",
       "      <th>Cu_Ft_</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Count</th>\n",
       "      <th>Client Name</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Order Delivery Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75767</th>\n",
       "      <td>105310</td>\n",
       "      <td>LD28357 (Load ID)</td>\n",
       "      <td>2023-04-24 10:00:00</td>\n",
       "      <td>2023-04-28 07:00</td>\n",
       "      <td>2023-04-27 13:00:00</td>\n",
       "      <td>2023-04-28 08:00</td>\n",
       "      <td>CA-EV</td>\n",
       "      <td>91752</td>\n",
       "      <td>NJ-HS</td>\n",
       "      <td>8861</td>\n",
       "      <td>...</td>\n",
       "      <td>2733.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6600.00</td>\n",
       "      <td>3337675</td>\n",
       "      <td>13.50</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CYMAX STORES</td>\n",
       "      <td>202.82</td>\n",
       "      <td>2023-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75768</th>\n",
       "      <td>105310</td>\n",
       "      <td>LD28357 (Load ID)</td>\n",
       "      <td>2023-04-24 10:00:00</td>\n",
       "      <td>2023-04-28 07:00</td>\n",
       "      <td>2023-04-27 13:00:00</td>\n",
       "      <td>2023-04-28 08:00</td>\n",
       "      <td>CA-EV</td>\n",
       "      <td>91752</td>\n",
       "      <td>NJ-HS</td>\n",
       "      <td>8861</td>\n",
       "      <td>...</td>\n",
       "      <td>2733.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6600.00</td>\n",
       "      <td>3337823</td>\n",
       "      <td>12.22</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CYMAX STORES</td>\n",
       "      <td>178.42</td>\n",
       "      <td>2023-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75769</th>\n",
       "      <td>263282</td>\n",
       "      <td>LD24949 (Load ID)</td>\n",
       "      <td>2023-02-10 15:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-02-11 07:00:00</td>\n",
       "      <td>2023-02-11 07:00</td>\n",
       "      <td>GA-SL</td>\n",
       "      <td>31326</td>\n",
       "      <td>NC-SD</td>\n",
       "      <td>27263</td>\n",
       "      <td>...</td>\n",
       "      <td>320.0</td>\n",
       "      <td>1</td>\n",
       "      <td>885.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75770</th>\n",
       "      <td>265679</td>\n",
       "      <td>LD27832 (Load ID)</td>\n",
       "      <td>2023-04-06 18:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-07 07:00:00</td>\n",
       "      <td>2023-04-06 21:41</td>\n",
       "      <td>GA-SL</td>\n",
       "      <td>31326</td>\n",
       "      <td>NC-SD</td>\n",
       "      <td>27263</td>\n",
       "      <td>...</td>\n",
       "      <td>320.0</td>\n",
       "      <td>1</td>\n",
       "      <td>858.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75771</th>\n",
       "      <td>9039767</td>\n",
       "      <td>LD28116 (Load ID)</td>\n",
       "      <td>2023-04-14 14:00:00</td>\n",
       "      <td>2023-04-14 14:00</td>\n",
       "      <td>2023-04-15 13:00:00</td>\n",
       "      <td>2023-04-15 07:30</td>\n",
       "      <td>CA-EV</td>\n",
       "      <td>85043</td>\n",
       "      <td>CA-EV</td>\n",
       "      <td>91752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2175.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       manifest_num  Primary Reference  Target Ship (Late)      Arrival Date  \\\n",
       "75767        105310  LD28357 (Load ID) 2023-04-24 10:00:00  2023-04-28 07:00   \n",
       "75768        105310  LD28357 (Load ID) 2023-04-24 10:00:00  2023-04-28 07:00   \n",
       "75769        263282  LD24949 (Load ID) 2023-02-10 15:00:00               NaN   \n",
       "75770        265679  LD27832 (Load ID) 2023-04-06 18:00:00               NaN   \n",
       "75771       9039767  LD28116 (Load ID) 2023-04-14 14:00:00  2023-04-14 14:00   \n",
       "\n",
       "      Target Delivery (Late)   Actual Delivery Origin Code  Origin Zip  \\\n",
       "75767    2023-04-27 13:00:00  2023-04-28 08:00       CA-EV       91752   \n",
       "75768    2023-04-27 13:00:00  2023-04-28 08:00       CA-EV       91752   \n",
       "75769    2023-02-11 07:00:00  2023-02-11 07:00       GA-SL       31326   \n",
       "75770    2023-04-07 07:00:00  2023-04-06 21:41       GA-SL       31326   \n",
       "75771    2023-04-15 13:00:00  2023-04-15 07:30       CA-EV       85043   \n",
       "\n",
       "      Dest Code  Dest Zip  ... Load Total Distance  Legs per Load Leg Cost  \\\n",
       "75767     NJ-HS      8861  ...              2733.0              1  6600.00   \n",
       "75768     NJ-HS      8861  ...              2733.0              1  6600.00   \n",
       "75769     NC-SD     27263  ...               320.0              1   885.01   \n",
       "75770     NC-SD     27263  ...               320.0              1   858.69   \n",
       "75771     CA-EV     91752  ...                 0.0              0  2175.00   \n",
       "\n",
       "       Order #  Cu_Ft_  Weight  Count   Client Name  Amount  \\\n",
       "75767  3337675   13.50    50.0    1.0  CYMAX STORES  202.82   \n",
       "75768  3337823   12.22    26.0    1.0  CYMAX STORES  178.42   \n",
       "75769      NaN     NaN     NaN    NaN           NaN     NaN   \n",
       "75770      NaN     NaN     NaN    NaN           NaN     NaN   \n",
       "75771      NaN     NaN     NaN    NaN           NaN     NaN   \n",
       "\n",
       "      Order Delivery Date  \n",
       "75767          2023-05-02  \n",
       "75768          2023-05-03  \n",
       "75769                 NaN  \n",
       "75770                 NaN  \n",
       "75771                 NaN  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_table.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03c3bcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_table['Manifest Cubes'] = fact_table.groupby(['Primary Reference', 'revised_from_to', 'manifest_num'])['Cu_Ft_'].transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e108a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_table['Leg Cubes'] = fact_table.groupby(['Primary Reference', 'revised_from_to'])['Cu_Ft_'].transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc860793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['manifest_num', 'Primary Reference', 'Target Ship (Late)',\n",
       "       'Arrival Date', 'Target Delivery (Late)', 'Actual Delivery',\n",
       "       'Origin Code', 'Origin Zip', 'Dest Code', 'Dest Zip', 'Carrier',\n",
       "       'Carrier Total', 'Invoice Date', 'Invoice Number', 'Invoice Charge',\n",
       "       'Invoice Total Line Haul', 'Invoice Total Fuel', 'from_to',\n",
       "       'from_to_zip', 'Code;Zip', 'OriginCode;Zip', 'lane', 'zips', 'size',\n",
       "       'Vendor Pickup?', 'revised_from_to', 'revised_zips', 'count_leg',\n",
       "       'zip_distance', 'Adjusted Distance', 'Load Total Distance',\n",
       "       'Legs per Load', 'Leg Cost', 'Order #', 'Cu_Ft_', 'Weight', 'Count',\n",
       "       'Client Name', 'Amount', 'Order Delivery Date', 'Manifest Cubes',\n",
       "       'Leg Cubes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "528ef682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate number of manifests per leg\n",
    "manifests_per_leg = fact_table.groupby(['Primary Reference', 'revised_from_to']).manifest_num.nunique().reset_index(name='Manifests Per Leg')\n",
    "\n",
    "# merge manifests_per_leg with fact_table\n",
    "fact_table = pd.merge(fact_table, manifests_per_leg, on=['Primary Reference', 'revised_from_to'])\n",
    "\n",
    "# allocate leg cost to manifests\n",
    "fact_table['Manifest Cost'] = np.where(fact_table['Leg Cubes'] <= 0,\n",
    "                                       fact_table['Leg Cost'] / fact_table['Manifests Per Leg'].clip(lower=1),\n",
    "                                       fact_table['Leg Cost'] * fact_table['Manifest Cubes'] / fact_table['Leg Cubes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b980942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate number of manifests per leg\n",
    "orders_per_manifest = fact_table.groupby(['Primary Reference', 'revised_from_to', 'manifest_num'])['Order #'].nunique().reset_index(name='Orders Per Manifest')\n",
    "\n",
    "# merge orders_per_leg with fact_table\n",
    "fact_table = pd.merge(fact_table, orders_per_manifest, on=['Primary Reference', 'revised_from_to', 'manifest_num'])\n",
    "\n",
    "# allocate leg cost to manifests\n",
    "fact_table['POM Cost'] = np.where(fact_table['Manifest Cubes'] <= 0,\n",
    "                                  fact_table['Manifest Cost'] / fact_table['Orders Per Manifest'].clip(lower=1),\n",
    "                                  fact_table['Manifest Cost'] * fact_table['Cu_Ft_'] / fact_table['Manifest Cubes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2a36f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_table = fact_table.rename(columns={'revised_from_to': 'Leg', 'revised_zips': 'Leg Zips',\n",
    "                              'count_leg': 'Leg Instance per Load', 'Cu_Ft_': 'Order Cubes',\n",
    "                              'zip_distance': 'Actual Distance'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20e015aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(OUTPUT_PATH + \"Product.csv\"):\n",
    "    old_data = pd.read_csv(OUTPUT_PATH + \"Product.csv\")\n",
    "    references = set(fact_table[\"Primary Reference\"])\n",
    "    old_data = old_data[~old_data[\"Primary Reference\"].isin(references)]\n",
    "    final = pd.concat([old_data, fact_table])\n",
    "else:\n",
    "    final = fact_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27927ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shahmir.tariq\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning: invalid value encountered in cast\n",
      "  values = values.astype(str)\n"
     ]
    }
   ],
   "source": [
    "final.to_csv(OUTPUT_PATH + \"Product.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ad1db817",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in os.listdir(REPORT_PATH):\n",
    "    file_path = os.path.join(REPORT_PATH, file_name)\n",
    "    if os.path.isfile(file_path) and file_name.endswith('.csv'):\n",
    "        os.remove(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
